{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones Avanzadas: Pandas vs Polars vs Data.table\n",
    "\n",
    "Este notebook se centra en operaciones avanzadas y transformaciones complejas de datos para comparar el rendimiento de las tres librerías.\n",
    "\n",
    "## Contenido\n",
    "1. Configuración y Preparación\n",
    "2. Joins Complejos\n",
    "3. Window Functions\n",
    "4. Operaciones de Pivote\n",
    "5. Agregaciones Complejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import datatable as dt\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.utils import plot_benchmark_results, calculate_speedup\n",
    "from src.benchmarks import create_sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación de Datos Complejos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Crear datasets más complejos para operaciones avanzadas\n",
    "def create_complex_datasets(n_rows: int):\n",
    "    # Dataset principal\n",
    "    main_data = {\n",
    "        'id': np.arange(n_rows),\n",
    "        'value': np.random.randn(n_rows),\n",
    "        'category': np.random.choice(['A', 'B', 'C'], n_rows),\n",
    "        'date': pd.date_range('2023-01-01', periods=n_rows),\n",
    "        'group': np.random.choice(['X', 'Y', 'Z'], n_rows)\n",
    "    }\n",
    "    \n",
    "    # Dataset secundario para joins\n",
    "    secondary_data = {\n",
    "        'id': np.random.choice(np.arange(n_rows), size=n_rows//2),\n",
    "        'aux_value': np.random.randn(n_rows//2),\n",
    "        'aux_category': np.random.choice(['P', 'Q', 'R'], n_rows//2)\n",
    "    }\n",
    "    \n",
    "    return main_data, secondary_data\n",
    "\n",
    "N_ROWS = 1_000_000\n",
    "main_data, secondary_data = create_complex_datasets(N_ROWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Joins Complejos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def benchmark_joins():\n",
    "    results = {}\n",
    "    \n",
    "    # Pandas\n",
    "    start = time()\n",
    "    df1_pd = pd.DataFrame(main_data)\n",
    "    df2_pd = pd.DataFrame(secondary_data)\n",
    "    result_pd = df1_pd.merge(df2_pd, on='id', how='left')\n",
    "    results['pandas'] = time() - start\n",
    "    \n",
    "    # Polars\n",
    "    start = time()\n",
    "    df1_pl = pl.DataFrame(main_data)\n",
    "    df2_pl = pl.DataFrame(secondary_data)\n",
    "    result_pl = df1_pl.join(df2_pl, on='id', how='left')\n",
    "    results['polars'] = time() - start\n",
    "    \n",
    "    # Data.table\n",
    "    start = time()\n",
    "    df1_dt = dt.Frame(main_data)\n",
    "    df2_dt = dt.Frame(secondary_data)\n",
    "    result_dt = df1_dt[:, :, dt.join(df2_dt)]\n",
    "    results['datatable'] = time() - start\n",
    "    \n",
    "    return results\n",
    "\n",
    "join_results = benchmark_joins()\n",
    "plot_benchmark_results(join_results, title='Tiempo de Joins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def benchmark_window_operations():\n",
    "    results = {}\n",
    "    \n",
    "    # Pandas\n",
    "    start = time()\n",
    "    df_pd = pd.DataFrame(main_data)\n",
    "    result_pd = df_pd.assign(\n",
    "        rolling_mean=df_pd.groupby('category')['value'].transform(\n",
    "            lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    "        ),\n",
    "        cumulative_sum=df_pd.groupby('category')['value'].transform('cumsum')\n",
    "    )\n",
    "    results['pandas'] = time() - start\n",
    "    \n",
    "    # Polars\n",
    "    start = time()\n",
    "    df_pl = pl.DataFrame(main_data)\n",
    "    result_pl = df_pl.with_columns([\n",
    "        pl.col('value').rolling_mean(7).over('category').alias('rolling_mean'),\n",
    "        pl.col('value').cum_sum().over('category').alias('cumulative_sum')\n",
    "    ])\n",
    "    results['polars'] = time() - start\n",
    "    \n",
    "    # Data.table\n",
    "    start = time()\n",
    "    df_dt = dt.Frame(main_data)\n",
    "    result_dt = df_dt[:, {\n",
    "        'rolling_mean': dt.roll_mean(dt.f.value, window=7),\n",
    "        'cumulative_sum': dt.cumsum(dt.f.value)\n",
    "    }, by('category')]\n",
    "    results['datatable'] = time() - start\n",
    "    \n",
    "    return results\n",
    "\n",
    "window_results = benchmark_window_operations()\n",
    "plot_benchmark_results(window_results, title='Tiempo de Operaciones Window')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Operaciones de Pivote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def benchmark_pivot_operations():\n",
    "    results = {}\n",
    "    \n",
    "    # Pandas\n",
    "    start = time()\n",
    "    df_pd = pd.DataFrame(main_data)\n",
    "    pivot_pd = df_pd.pivot_table(\n",
    "        values='value',\n",
    "        index='category',\n",
    "        columns='group',\n",
    "        aggfunc=['mean', 'count', 'std']\n",
    "    )\n",
    "    results['pandas'] = time() - start\n",
    "    \n",
    "    # Polars\n",
    "    start = time()\n",
    "    df_pl = pl.DataFrame(main_data)\n",
    "    pivot_pl = df_pl.pivot(\n",
    "        values='value',\n",
    "        index='category',\n",
    "        columns='group',\n",
    "        aggregate_function=['mean', 'count', 'std']\n",
    "    )\n",
    "    results['polars'] = time() - start\n",
    "    \n",
    "    # Data.table (simulación de pivot)\n",
    "    start = time()\n",
    "    df_dt = dt.Frame(main_data)\n",
    "    pivot_dt = df_dt[:, {'mean': dt.mean(dt.f.value),\n",
    "                         'count': dt.count(),\n",
    "                         'std': dt.sd(dt.f.value)},\n",
    "                    by('category,group')]\n",
    "    results['datatable'] = time() - start\n",
    "    \n",
    "    return results\n",
    "\n",
    "pivot_results = benchmark_pivot_operations()\n",
    "plot_benchmark_results(pivot_results, title='Tiempo de Operaciones Pivot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agregaciones Complejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def benchmark_complex_aggregations():\n",
    "    results = {}\n",
    "    \n",
    "    # Pandas\n",
    "    start = time()\n",
    "    df_pd = pd.DataFrame(main_data)\n",
    "    agg_pd = df_pd.groupby(['category', 'group']).agg({\n",
    "        'value': ['mean', 'std', 'count', 'sum',\n",
    "                 lambda x: x.quantile(0.25),\n",
    "                 lambda x: x.quantile(0.75)]\n",
    "    }).reset_index()\n",
    "    results['pandas'] = time() - start\n",
    "    \n",
    "    # Polars\n",
    "    start = time()\n",
    "    df_pl = pl.DataFrame(main_data)\n",
    "    agg_pl = df_pl.groupby(['category', 'group']).agg([\n",
    "        pl.col('value').mean(),\n",
    "        pl.col('value').std(),\n",
    "        pl.col('value').count(),\n",
    "        pl.col('value').sum(),\n",
    "        pl.col('value').quantile(0.25),\n",
    "        pl.col('value').quantile(0.75)\n",
    "    ])\n",
    "    results['polars'] = time() - start\n",
    "    \n",
    "    # Data.table\n",
    "    start = time()\n",
    "    df_dt = dt.Frame(main_data)\n",
    "    agg_dt = df_dt[:, {\n",
    "        'mean': dt.mean(dt.f.value),\n",
    "        'std': dt.sd(dt.f.value),\n",
    "        'count': dt.count(),\n",
    "        'sum': dt.sum(dt.f.value),\n",
    "        'q25': dt.quantile(dt.f.value, 0.25),\n",
    "        'q75': dt.quantile(dt.f.value, 0.75)\n",
    "    }, by('category,group')]\n",
    "    results['datatable'] = time() - start\n",
    "    \n",
    "    return results\n",
    "\n",
    "agg_results = benchmark_complex_aggregations()\n",
    "plot_benchmark_results(agg_results, title='Tiempo de Agregaciones Complejas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis de Resultados\n",
    "\n",
    "Vamos a calcular los speedups relativos a Pandas para cada operación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "all_results = {\n",
    "    'Joins': join_results,\n",
    "    'Window': window_results,\n",
    "    'Pivot': pivot_results,\n",
    "    'Aggregation': agg_results\n",
    "}\n",
    "\n",
    "speedups = {}\n",
    "for operation, results in all_results.items():\n",
    "    speedups[operation] = calculate_speedup(results)\n",
    "\n",
    "speedup_df = pd.DataFrame(speedups)\n",
    "print(\"\\nSpeedup relativo a Pandas (>1 significa más rápido que Pandas):\")\n",
    "print(speedup_df)\n",
    "\n",
    "# Visualizar speedups\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(speedup_df, annot=True, fmt='.2f', cmap='YlOrRd')\n",
    "plt.title('Speedup Relativo a Pandas')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}
